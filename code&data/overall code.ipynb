{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2016122015_SunwooKim_Codes",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu-RX4pGDvuB",
        "colab_type": "text"
      },
      "source": [
        "**DL Final Project**\n",
        "\n",
        "**2016122015**\n",
        "\n",
        "**Applied Statistics**\n",
        "\n",
        "**Sunwoo Kim**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpJeLROw9dgT",
        "colab_type": "text"
      },
      "source": [
        "Project : \n",
        "\n",
        "***Evaluating the Prediction Power of RNN, LSTM, GRU***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz0quxqAPsPb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "** WARNING **\n",
        "\n",
        "There are some codes that takes huge time(codes of 3.5)\n",
        "\n",
        "***Please do not Operate Entire RUNTIME in Once***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6gpoyO5S5YZ",
        "colab_type": "text"
      },
      "source": [
        "About the Codes \n",
        "\n",
        "0. Packages\n",
        "\n",
        "1. About Data\n",
        "\n",
        "2. Defining some Functions\n",
        "\n",
        "3. The Training and Predicting\n",
        "\n",
        "4. Statistical Model SARIMAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D-aXWNpEIRo",
        "colab_type": "text"
      },
      "source": [
        "0. Importing the necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekLYpoP9EHKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Basic Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "sns.set()\n",
        "from statistics import mean\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "## The RNN \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, GRU, Activation, Dropout\n",
        "from keras import optimizers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "## The Statistics\n",
        "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
        "import statsmodels.api as sm\n",
        "import itertools\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So3a_yTJDYSp",
        "colab_type": "text"
      },
      "source": [
        "1. Importing and preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwmgfUgU9bxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDnMS8O6DpPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## The basic Raw Data\n",
        "fire = pd.read_csv('/content/gdrive/My Drive/STA_DL/forest_fire.csv', header = None)\n",
        "\n",
        "train_data = fire[:250]\n",
        "test_data = fire[250:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6E2zNZSErSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Producing log train data\n",
        "## The data that has a value of 0 should get value greater than 1 to get into the log\n",
        "train_data1 = train_data.copy()\n",
        "train_data1[train_data1 < 2] = 1 \n",
        "log_train_data = np.log(train_data1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKhZ6XvKRyK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Data Visualizing\n",
        "\n",
        "Month_1 = []\n",
        "for i in range(12) : \n",
        "  Month_2 = []\n",
        "  for s in range(19) : \n",
        "    data = int(fire.iloc[i+s*12])\n",
        "    Month_2.append(data)\n",
        "  Month_1.append(mean(Month_2))\n",
        "\n",
        "plt.figure(figsize = (16,6)) \n",
        "plt.subplot(121) ; plt.plot(fire) ;plt.title('Total Occurence')\n",
        "plt.subplot(122) ; plt.bar(range(len(Month_1)), Month_1) ; plt.title('Mean Monthly Occurence')\n",
        "plt.show()\n",
        "print(fire.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9tXKCreEquy",
        "colab_type": "text"
      },
      "source": [
        "2. Generating The Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_SBhkm9Gl3C",
        "colab_type": "text"
      },
      "source": [
        "2.1) Function for the Data Generating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAAAdW2rFCwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Producing Input and Label of RNN \n",
        "\n",
        "def input_generator(x, n) : \n",
        "  x1 = np.zeros((int(x.shape[0]-n+1)*n)).reshape(int(x.shape[0]-n+1), n)\n",
        "  for i in range(int(x.shape[0]-n+1)) : \n",
        "    for s in range(n) : \n",
        "      x1[i,s] = int(x[i:i+n].iloc[s])\n",
        "  return(x1)\n",
        "\n",
        "def y_generator (y,n) : \n",
        "  y1 = y[n:]\n",
        "  return(y1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qqoCmirFEJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## rnn_x, rnn_y = The Raw Training Data Set\n",
        "## log_rnn_x, log_rnn_y = The log Training Data Set\n",
        "\n",
        "rnn_x1 = input_generator(train_data, 12)[:-1]\n",
        "rnn_x = rnn_x1.reshape(rnn_x1.shape[0], 1, rnn_x1.shape[1])\n",
        "rnn_y = y_generator(train_data, 12)\n",
        "\n",
        "rnn_x2 = input_generator(log_train_data, 12)[:-1]\n",
        "log_rnn_x = rnn_x2.reshape(rnn_x2.shape[0], 1, rnn_x2.shape[1])\n",
        "log_rnn_y = y_generator(log_train_data, 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTehbTtbFe_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Here it Produces the Prediction Values\n",
        "## This automatically takes the previous predicted value to the input of next prediction steps\n",
        "## The final Prediction Value of '18.01 to '19.12 comes out as a numpy array\n",
        "\n",
        "def prediction_generator(model) : \n",
        "  final_v = []\n",
        "  x1 = np.concatenate([rnn_x[-1][0][1:],[int(rnn_y.iloc[-1])]])\n",
        "  for i in range(24) : \n",
        "    new_v = int(model.predict(x1.reshape(1,1,12)))\n",
        "    final_v.append(new_v)\n",
        "    x1 = np.concatenate([x1[1:], np.array([new_v])])\n",
        "  return(final_v)\n",
        "\n",
        "def log_prediction_generator(model) : \n",
        "  final_v = []\n",
        "  x1 = np.concatenate([log_rnn_x[-1][0][1:],[int(log_rnn_y.iloc[-1])]])\n",
        "  for i in range(24) : \n",
        "    new_v = int(model.predict(x1.reshape(1,1,12)))\n",
        "    final_v.append(new_v)\n",
        "    x1 = np.concatenate([x1[1:], np.array([new_v])])\n",
        "  return(final_v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2QkScGCGpxI",
        "colab_type": "text"
      },
      "source": [
        "2.2) Funtion for the Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTz_482AGaB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_layer_SRNN (n, d) : \n",
        "  model = Sequential()\n",
        "  model.add(SimpleRNN(n, input_shape = (1,12), return_sequences = False, activation = 'relu'))\n",
        "  model.add(Dropout(d))\n",
        "  model.add(Dense(1, activation = 'relu'))\n",
        "  model.compile(loss = 'mse', optimizer = 'adam')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv39O_7nFknA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_layer_LSTM (n, d) : \n",
        "  model = Sequential()\n",
        "  model.add(LSTM(n, input_shape = (1,12), return_sequences = False, activation = 'relu'))\n",
        "  model.add(Dropout(d))\n",
        "  model.add(Dense(1, activation = 'relu'))\n",
        "  model.compile(loss = 'mse', optimizer = 'adam')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2j_GYiGzy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_layer_GRU (n, d) : \n",
        "  model = Sequential()\n",
        "  model.add(GRU(n, input_shape = (1,12), return_sequences = False, activation = 'relu'))\n",
        "  model.add(Dropout(d))\n",
        "  model.add(Dense(1, activation = 'relu'))\n",
        "  model.compile(loss = 'mse', optimizer = 'adam')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAuV24i7G0pZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def double_layer_SRNN(n1,n2,d) :\n",
        "  model = Sequential()\n",
        "  model.add(SimpleRNN(n1, input_shape =(1,12), return_sequences =  True, activation = 'relu'))\n",
        "  model.add(Dropout(d))\n",
        "  model.add(SimpleRNN(n2, return_sequences = False,activation = 'relu'))\n",
        "  model.add(Dropout(d))\n",
        "  model.add(Dense(1, activation = 'relu'))\n",
        "  model.compile(loss = 'mse', optimizer = 'adam')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWdE9Y59FhnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def double_layer_LSTM(n1, n2, d) :\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(n1, input_shape =(1,12), return_sequences =  True, activation = 'relu'))\n",
        "  model.add(Dropout(d))\n",
        "  model.add(LSTM(n2, return_sequences = False,activation = 'relu'))\n",
        "  model.add(Dropout(d))\n",
        "  model.add(Dense(1, activation = 'relu'))\n",
        "  model.compile(loss = 'mse', optimizer = 'adam')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-fNZ7MpG9cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def double_layer_GRU(n1, n2, d) :\n",
        "  model = Sequential()\n",
        "  model.add(GRU(n1, input_shape =(1,12), return_sequences =  True, activation = 'relu'))\n",
        "  model.add(Dropout(d))\n",
        "  model.add(GRU(n2, return_sequences = False,activation = 'relu'))\n",
        "  model.add(Dropout(d))\n",
        "  model.add(Dense(1, activation = 'relu'))\n",
        "  model.compile(loss = 'mse', optimizer = 'adam')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV4xxzj9HKHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## To obtain the optimal nodes number, We can Get the Result Table\n",
        "def single_layer_result(m,a,b) :\n",
        "  res_t = pd.DataFrame(data = {'Node_Number' : [0], 'Mean_Err' : [0], 'Pred_Err' : [0]}, columns = ['Node_Number', 'Mean_Err', 'Pred_Err'])\n",
        "  for i in range(a,b) : \n",
        "    model = m(i, 0.3)\n",
        "    hist = model.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "    mean_loss = mean(hist.history['loss'][15:])\n",
        "    predy = prediction_generator(model)\n",
        "    pred_loss = mean_squared_error(predy, test_data)\n",
        "    Partial = pd.DataFrame(data = {'Node_Number' : [i], 'Mean_Err' : [mean_loss], 'Pred_Err' : [pred_loss]}, columns = ['Node_Number', 'Mean_Err', 'Pred_Err'])\n",
        "    res_t = pd.concat([res_t, Partial], axis =0, join = 'outer')\n",
        "  return res_t "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyaskX1eNsB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def double_layer_result(m,a,b,c,d) :\n",
        "  res_t = pd.DataFrame(data = {'Node_Number1' : [0], 'Node_Number2' : [0], 'Mean_Err' : [0], 'Pred_Err' : [0]}, columns = ['Node_Number1', 'Node_Number2','Mean_Err', 'Pred_Err'])\n",
        "  for i in range(a,b) :\n",
        "    for s in range(c,d) :  \n",
        "      model = m(i, s, 0.3)\n",
        "      hist = model.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "      mean_loss = mean(hist.history['loss'][15:])\n",
        "      predy = prediction_generator(model)\n",
        "      pred_loss = mean_squared_error(predy, test_data)\n",
        "      Partial = pd.DataFrame(data = {'Node_Number1' : [i], 'Node_Number2' : [s], 'Mean_Err' : [mean_loss], 'Pred_Err' : [pred_loss]}, columns = ['Node_Number1', 'Node_Number2','Mean_Err', 'Pred_Err'])\n",
        "      res_t = pd.concat([res_t, Partial], axis =0, join = 'outer')\n",
        "  return res_t "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2chpBAWoHfHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Proof for the importance of batch_Selection\n",
        "## That specific nodes doesn't matter, but the range does exist\n",
        "def Simulation_T_S(m,a,b) :\n",
        "  res_t = pd.DataFrame(data = {'Node_Number' : [0], 'Mean_Err' : [0], 'Pred_Err' : [0]}, columns = ['Node_Number', 'Mean_Err', 'Pred_Err'])\n",
        "  for i in range(a,b) : \n",
        "    e_table = []\n",
        "    p_table = []\n",
        "    for s in range(30) :\n",
        "      model = m(i, 0.3)\n",
        "      hist = model.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "      mean_loss = mean(hist.history['loss'][15:])\n",
        "      predy = prediction_generator(model)\n",
        "      pred_loss = mean_squared_error(predy, test_data)\n",
        "      e_table.append(mean_loss)\n",
        "      p_table.append(pred_loss)\n",
        "    M_L = mean(e_table)\n",
        "    P_L = mean(p_table)\n",
        "    Partial = pd.DataFrame(data = {'Node_Number' : [i], 'Mean_Err' : [M_L], 'Pred_Err' : [P_L]}, columns = ['Node_Number', 'Mean_Err', 'Pred_Err'])\n",
        "    res_t = pd.concat([res_t, Partial], axis =0, join = 'outer')\n",
        "  return res_t "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BDONO1KH9Vi",
        "colab_type": "text"
      },
      "source": [
        "3. Getting the Training and Prediction Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSgUi6h6IEyK",
        "colab_type": "text"
      },
      "source": [
        "3.1) Log Data vs Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2yXyxUNHzsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model0_0 = single_layer_SRNN(50, 0.3)\n",
        "model0_0.summary()\n",
        "hist1 = model0_0.fit(log_rnn_x, log_rnn_y, batch_size = 40, epochs = 25)\n",
        "plt.plot(hist1.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "predy = np.exp(log_prediction_generator(model1))\n",
        "pred_loss = mean_squared_error(predy, test_data)\n",
        "print(pred_loss)\n",
        "x1 = np.arange(0, 24)\n",
        "plt.plot( x1, predy, x1, test_data, 'r-')\n",
        "plt.legend(('Pred', 'True'))\n",
        "plt.title('log Data')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_uFHQiaHxpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model0_1 = single_layer_SRNN(50, 0.3)\n",
        "model0_1.summary()\n",
        "hist1 = model0_1.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "plt.plot(hist1.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "predy = prediction_generator(model0_1)\n",
        "pred_loss = mean_squared_error(predy, test_data)\n",
        "print(pred_loss)\n",
        "x1 = np.arange(0, 24)\n",
        "plt.plot( x1, predy, x1, test_data, 'r-')\n",
        "plt.legend(('Pred', 'True'))\n",
        "plt.title('log Data')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW4TQ7QBIwvl",
        "colab_type": "text"
      },
      "source": [
        "3.1 Result. The Raw data gives better Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At1ost19I11I",
        "colab_type": "text"
      },
      "source": [
        "3.2) The Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypg0GcEiG9fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Single Layer Simple RNN\n",
        "model1 = single_layer_SRNN(40, 0.3)\n",
        "model1.summary()\n",
        "hist1 = model1.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "plt.plot(hist1.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "predy1 = prediction_generator(model1)\n",
        "pred_loss1 = mean_squared_error(predy1, test_data)\n",
        "print(pred_loss1)\n",
        "x1 = np.arange(0, 24)\n",
        "plt.plot( x1, predy1, x1, test_data, 'r-')\n",
        "plt.legend(('Pred', 'True'))\n",
        "plt.title('Prediction Err')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3D1Zql0JKQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Double Layer Simple RNN\n",
        "model2 = double_layer_SRNN(20, 60, 0.2)\n",
        "model2.summary()\n",
        "hist2 = model2.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "plt.plot(hist2.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "predy2 = prediction_generator(model2)\n",
        "pred_loss2 = mean_squared_error(predy2, test_data)\n",
        "print(pred_loss2)\n",
        "x1 = np.arange(0, 24)\n",
        "plt.plot( x1, predy2, x1, test_data, 'r-')\n",
        "plt.legend(('Pred', 'True'))\n",
        "plt.title('Prediction Err')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5om0bIyqJvRT",
        "colab_type": "text"
      },
      "source": [
        "3.3) The LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zWWKRPIJaFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Single Layer LSTM\n",
        "model3 = single_layer_LSTM(26, 0.3)\n",
        "model3.summary()\n",
        "hist3 = model3.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "plt.plot(hist3.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "predy3 = prediction_generator(model3)\n",
        "pred_loss3 = mean_squared_error(predy3, test_data)\n",
        "print(pred_loss3)\n",
        "x1 = np.arange(0, 24)\n",
        "plt.plot( x1, predy3, x1, test_data, 'r-')\n",
        "plt.legend(('Pred', 'True'))\n",
        "plt.title('Prediction Err')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IvaDA9gJ5Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Double Layer LSTM\n",
        "model4 = double_layer_LSTM(40, 40, 0.2)\n",
        "model4.summary()\n",
        "hist4 = model4.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "plt.plot(hist4.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "predy4 = prediction_generator(model4)\n",
        "pred_loss4 = mean_squared_error(predy4, test_data)\n",
        "print(pred_loss4)\n",
        "x1 = np.arange(0, 24)\n",
        "plt.plot( x1, predy4, x1, test_data, 'r-')\n",
        "plt.legend(('Pred', 'True'))\n",
        "plt.title('Prediction Err')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUd7VnuWLHvK",
        "colab_type": "text"
      },
      "source": [
        "3.4) The GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUYtv4VFLHHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Single Layer GRU\n",
        "model5 = single_layer_GRU(70, 0.3)\n",
        "model5.summary()\n",
        "hist5 = model5.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "plt.plot(hist5.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "predy5 = prediction_generator(model5)\n",
        "pred_loss5 = mean_squared_error(predy5, test_data)\n",
        "print(pred_loss5)\n",
        "x1 = np.arange(0, 24)\n",
        "plt.plot( x1, predy5, x1, test_data, 'r-')\n",
        "plt.legend(('Pred', 'True'))\n",
        "plt.title('Prediction Err')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTxw28N8G9nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Double Layer GRU\n",
        "model6 = double_layer_LSTM(60, 60, 0.2)\n",
        "model6.summary()\n",
        "hist6 = model6.fit(rnn_x, rnn_y, batch_size = 40, epochs = 25)\n",
        "plt.plot(hist6.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "predy6 = prediction_generator(model6)\n",
        "pred_loss6 = mean_squared_error(predy6, test_data)\n",
        "print(pred_loss6)\n",
        "x1 = np.arange(0, 24)\n",
        "plt.plot( x1, predy6, x1, test_data, 'r-')\n",
        "plt.legend(('Pred', 'True'))\n",
        "plt.title('Prediction Err')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DppPGLTRMkg7",
        "colab_type": "text"
      },
      "source": [
        "3.5) Trying with Various nodes number\n",
        "\n",
        "** WARNING **\n",
        "\n",
        "Following 3.5 codes takes Huge Time "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdPD9_0oMbl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Getting the Result for the range of nodes number 20 to 100\n",
        "Optimal_single_SRNN = single_layer_result(single_layer_SRNN, 20, 100)[1:]\n",
        "Optimal_single_LSTM = single_layer_result(single_layer_LSTM, 20, 100)[1:]\n",
        "Optimal_single_GRU = single_layer_result(single_layer_GRU, 20, 100)[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZy61NMoOlbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Getting the Result for the range of nodes number 20 to 60 or 40 to 80\n",
        "Optimal_double_SRNN = double_layer_result(double_layer_SRNN, 20, 60, 20, 60)[1:]\n",
        "Optimal_double_LSTM = double_layer_result(double_layer_LSTM, 20, 60, 20, 60)[1:]\n",
        "Optimal_double_GRU = double_layer_result(double_layer_GRU, 40, 80, 40, 80)[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOMNnWgNQQi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Simulation for the same nodes number various times \n",
        "## Simulation for the nodes from a to b for 30 times each\n",
        "## This is only for the Single Layer Model\n",
        "Simulation = Simulation_T_S(single_layer_LSTM,20,40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1cpTys3ShnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Visualizing the Simulation Result\n",
        "\n",
        "x1 = np.arange(20, 40)\n",
        "plt.plot(x1, Simulation.Mean_Err[1:])\n",
        "plt.xlabel('Node Number')\n",
        "plt.title('Mean Training Loss 10 times Simulation')\n",
        "plt.show()\n",
        "\n",
        "x2 = np.arange(20, 40)\n",
        "plt.plot(x2, Simulation.Pred_Err[1:])\n",
        "plt.xlabel('Node Number')\n",
        "plt.title('Mean Prediction Loss 10 times Simulation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICVu_K1eQ-NJ",
        "colab_type": "text"
      },
      "source": [
        "4) About Statistical Model\n",
        "\n",
        "Using SARIMAX "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAbDQqGdQ5Qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Drawing ACF, PACF for log_train_data\n",
        "print(plot_acf(log_train_data, lags = 40))\n",
        "print(plot_pacf(log_train_data, lags = 40))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHwuVazdRfc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decompose = sm.tsa.seasonal_decompose(log_train_data, model='add', freq = 12)\n",
        "fig = decompose.plot()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzpkODClR5tQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Searching for Optimal p, d, q value for the SARIMAX\n",
        "\n",
        "p = d = q = range(0, 3)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
        "\n",
        "d_pdq = []\n",
        "for i in range(27) :\n",
        "  if pdq[i][1] == 1 :\n",
        "    d_pdq.append(pdq[i])\n",
        "\n",
        "s_pdq = []\n",
        "for i in range(27) :\n",
        "  if seasonal_pdq[i][1] == 1 :\n",
        "    s_pdq.append(seasonal_pdq[i])\n",
        "\n",
        "final = pd.DataFrame(data = {'De_Seasonal' : [(0,0,0)], 'Seasonal' : [(0,0,0)], 'AIC' : [10000]}, columns = ['De_Seasonal', 'Seasonal', 'AIC'])\n",
        "for param in d_pdq:\n",
        "    for param_seasonal in s_pdq:\n",
        "        try:\n",
        "            mod = sm.tsa.statespace.SARIMAX(log_train_data,order=param,seasonal_order=param_seasonal,enforce_stationarity=False,enforce_invertibility=False)\n",
        "            results = mod.fit()\n",
        "            Partial = pd.DataFrame(data = {'De_Seasonal' : [param], 'Seasonal' : [param_seasonal], 'AIC' : results.aic}, columns = ['De_Seasonal', 'Seasonal', 'AIC'])\n",
        "            final = pd.concat([final, Partial], axis =0, join = 'outer')\n",
        "        except: \n",
        "            continue\n",
        "final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRprTzgkSEwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## The Result for the SARIMAX\n",
        "\n",
        "mod = sm.tsa.statespace.SARIMAX(\n",
        "                                #train_data,\n",
        "                                log_train_data,\n",
        "                                order=(1, 1, 1),\n",
        "                                seasonal_order=(1, 1, 0, 12),\n",
        "                                enforce_stationarity=False,\n",
        "                                enforce_invertibility=False)\n",
        "res = mod.fit()\n",
        "print(res.summary())\n",
        "\n",
        "res.plot_diagnostics(figsize = (18,8))\n",
        "plt.show()\n",
        "\n",
        "pred = res.get_prediction(start = 1, end = 24, dynamic = False)\n",
        "#y_pred = pred.predicted_mean\n",
        "y_pred = np.exp(pred.predicted_mean)\n",
        "print('Test MSE is', mean_squared_error(test_data[0], y_pred))\n",
        "\n",
        "x1 = np.arange(0, 24)\n",
        "plt.plot( x1, y_pred, x1, test_data, 'r-')\n",
        "plt.legend(('Pred', 'True'))\n",
        "plt.title('True Data and Predicted Data')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}